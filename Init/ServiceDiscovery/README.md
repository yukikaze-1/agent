# æœåŠ¡å‘ç°æ¶æ„å®æ–½æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬é¡¹ç›®å·²æˆåŠŸå®æ–½**æœåŠ¡å‘ç°æ¨¡å¼**ï¼Œæ›¿ä»£äº†åŸæœ‰çš„å¤–éƒ¨æœåŠ¡å¯åŠ¨æ¨¡å¼ã€‚æ–°æ¶æ„å…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

- âœ… **èŒè´£åˆ†ç¦»**: å¤–éƒ¨æœåŠ¡ç‹¬ç«‹éƒ¨ç½²ï¼Œä¸»ç¨‹åºä¸“æ³¨ä¸šåŠ¡é€»è¾‘
- âœ… **ç”Ÿäº§å°±ç»ª**: ç¬¦åˆå¾®æœåŠ¡éƒ¨ç½²æœ€ä½³å®è·µ
- âœ… **æ•…éšœéš”ç¦»**: å¤–éƒ¨æœåŠ¡æ•…éšœä¸å½±å“ä¸»ç¨‹åºå¯åŠ¨
- âœ… **æ°´å¹³æ‰©å±•**: æ”¯æŒæœåŠ¡å®ä¾‹åŠ¨æ€æ·»åŠ 
- âœ… **è¿ç»´å‹å¥½**: æœåŠ¡å¯ç‹¬ç«‹ç®¡ç†å’Œç›‘æ§

## ğŸ—ï¸ æ¶æ„å¯¹æ¯”

### æ—§æ¶æ„ï¼ˆå·²å¼ƒç”¨ï¼‰
```
ä¸»ç¨‹åº â†’ å¯åŠ¨å¤–éƒ¨æœåŠ¡ â†’ å¯åŠ¨å†…éƒ¨FastAPIä»£ç† â†’ ä¸šåŠ¡é€»è¾‘
```

### æ–°æ¶æ„ï¼ˆæ¨èï¼‰
```
å¤–éƒ¨æœåŠ¡ï¼ˆç‹¬ç«‹éƒ¨ç½²ï¼‰ â† æœåŠ¡å‘ç° â† å†…éƒ¨ä»£ç†æ¨¡å— â† ä¸»ç¨‹åºä¸šåŠ¡é€»è¾‘
```

## ğŸ“ æ–°å¢ç»„ä»¶

### 1. æœåŠ¡å‘ç°æ¨¡å— (`Init/ServiceDiscovery/`)
- `service_discovery_manager.py`: æœåŠ¡å‘ç°ç®¡ç†å™¨
- `service_connector.py`: å¤–éƒ¨æœåŠ¡è¿æ¥å™¨  
- `exceptions.py`: æœåŠ¡å‘ç°ç›¸å…³å¼‚å¸¸
- `config.yml`: æœåŠ¡å‘ç°é…ç½®

### 2. å†…éƒ¨ä»£ç†æ¨¡å—
- `Module/LLM/LLMProxy.py`: LLMæœåŠ¡ä»£ç†
- `Module/TTS/TTSProxy.py`: TTSæœåŠ¡ä»£ç†
- `Module/STT/STTProxy.py`: STTæœåŠ¡ä»£ç†

### 3. æ›´æ–°çš„åˆå§‹åŒ–æµç¨‹
- `Init/Init.py`: æ”¯æŒæœåŠ¡å‘ç°æ¨¡å¼çš„ç³»ç»Ÿåˆå§‹åŒ–å™¨

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤1: éƒ¨ç½²å¤–éƒ¨æœåŠ¡

```bash
# 1. å¯åŠ¨Consul
consul agent -dev -client 0.0.0.0

# 2. å¯åŠ¨Ollama
ollama serve

# 3. å¯åŠ¨GPTSoVitsæœåŠ¡
cd /path/to/GPTSoVits
python GPTSoVits_api.py -a 0.0.0.0 -p 9880

# 4. å¯åŠ¨SenseVoiceæœåŠ¡
cd /path/to/SenseVoice  
python server.py --port 20060
```

### æ­¥éª¤2: æœåŠ¡æ³¨å†Œ

å¤–éƒ¨æœåŠ¡éœ€è¦åœ¨Consulä¸­æ³¨å†Œï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ï¼š

**æ‰‹åŠ¨æ³¨å†Œ**:
```bash
# æ³¨å†ŒOllamaæœåŠ¡
curl -X PUT http://localhost:8500/v1/agent/service/register \
  -d '{
    "ID": "ollama_server",
    "Name": "ollama_server", 
    "Address": "127.0.0.1",
    "Port": 11434,
    "Check": {
      "HTTP": "http://127.0.0.1:11434/api/tags",
      "Interval": "10s"
    }
  }'
```

**è‡ªåŠ¨æ³¨å†Œ**ï¼ˆæ¨èï¼‰:
ä½¿ç”¨æœåŠ¡è‡ªæ³¨å†Œæœºåˆ¶ï¼Œåœ¨æœåŠ¡å¯åŠ¨æ—¶è‡ªåŠ¨æ³¨å†Œåˆ°Consulã€‚

### æ­¥éª¤3: å¯åŠ¨ä¸»ç¨‹åº

```python
from Init.Init import SystemInitializer

# ä½¿ç”¨æœåŠ¡å‘ç°æ¨¡å¼
initializer = SystemInitializer(use_service_discovery=True)
result = initializer.initialize_all()

if result.success:
    print("âœ… ç³»ç»Ÿå¯åŠ¨æˆåŠŸ")
else:
    print(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {result.message}")
```

### æ­¥éª¤4: ä½¿ç”¨ä»£ç†æ¨¡å—

```python
import asyncio
from Module.LLM.LLMProxy import create_llm_proxy
from Module.TTS.TTSProxy import create_tts_proxy

async def main():
    # åˆ›å»ºLLMä»£ç†
    llm = await create_llm_proxy()
    response = await llm.chat("Hello!")
    
    # åˆ›å»ºTTSä»£ç†
    tts = await create_tts_proxy()
    audio_file = await tts.synthesize("ä½ å¥½ä¸–ç•Œ")
    
    # æ¸…ç†èµ„æº
    await llm.cleanup()
    await tts.cleanup()

asyncio.run(main())
```

## ğŸ³ Dockeréƒ¨ç½²ç¤ºä¾‹

### docker-compose.yml
```yaml
version: '3.8'

services:
  # æœåŠ¡æ³¨å†Œä¸­å¿ƒ
  consul:
    image: consul:latest
    ports:
      - "8500:8500"
    command: "agent -dev -client 0.0.0.0"

  # LLMæœåŠ¡
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

  # TTSæœåŠ¡
  gpt-sovits:
    build: ./services/gpt-sovits
    ports:
      - "9880:9880"

  # ä¸»ç¨‹åº
  agent-core:
    build: .
    depends_on:
      - consul
      - ollama
      - gpt-sovits
    environment:
      - CONSUL_URL=http://consul:8500
    volumes:
      - ./logs:/app/logs

volumes:
  ollama_data:
```

## âš™ï¸ é…ç½®è¯´æ˜

### æœåŠ¡å‘ç°é…ç½® (`Init/ServiceDiscovery/config.yml`)

```yaml
service_discovery:
  # å¿…éœ€æœåŠ¡åˆ—è¡¨
  required_services:
    - "ollama_server"
    - "GPTSoVits_server" 
    - "SenseVoice_server"

  # æœåŠ¡æ˜ å°„
  service_mapping:
    "ollama_server": "llm_service"
    "GPTSoVits_server": "tts_service"
    "SenseVoice_server": "stt_service"

  # å¥åº·æ£€æŸ¥
  health_check:
    timeout: 5
    retry_count: 3
    retry_delay: 2
```

### ä»£ç†æ¨¡å—é…ç½®ç¤ºä¾‹

```yaml
# LLMä»£ç†é…ç½®
llm_proxy:
  consul_url: "http://127.0.0.1:8500"
  default_model: "qwen2.5"
  request_timeout: 120.0
  max_retries: 3

# TTSä»£ç†é…ç½®  
tts_proxy:
  consul_url: "http://127.0.0.1:8500"
  save_dir: "${AGENT_HOME}/Temp"
  default_character: "Elysia"
  characters:
    Elysia:
      gpt_path: "models/gpt.ckpt"
      sovits_path: "models/sovits.pth"
      ref_audio: "audio/ref.wav"
      ref_audio_text: "ä½ å¥½ï¼Œæˆ‘æ˜¯çˆ±è‰å¸Œé›…ã€‚"
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æœåŠ¡å‘ç°å¤±è´¥**
   ```
   é”™è¯¯: Service 'ollama_server' not found
   è§£å†³: æ£€æŸ¥æœåŠ¡æ˜¯å¦åœ¨Consulä¸­æ­£ç¡®æ³¨å†Œ
   ```

2. **è¿æ¥è¶…æ—¶**
   ```
   é”™è¯¯: Failed to connect to service
   è§£å†³: æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒæœåŠ¡å¥åº·çŠ¶æ€
   ```

3. **ä»£ç†åˆå§‹åŒ–å¤±è´¥**
   ```
   é”™è¯¯: LLM service not available
   è§£å†³: ç¡®ä¿å¤–éƒ¨LLMæœåŠ¡æ­£åœ¨è¿è¡Œå¹¶å·²æ³¨å†Œ
   ```

### è°ƒè¯•å‘½ä»¤

```bash
# æ£€æŸ¥ConsulæœåŠ¡çŠ¶æ€
curl http://localhost:8500/v1/agent/services

# æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
curl http://localhost:8500/v1/health/service/ollama_server

# æµ‹è¯•æœåŠ¡è¿æ¥
curl http://localhost:11434/api/tags
```

## ğŸ“Š ç›‘æ§ä¸æ—¥å¿—

### æ—¥å¿—ä½ç½®
- æœåŠ¡å‘ç°: `Log/Other/ServiceDiscovery.log`
- å†…éƒ¨ä»£ç†: `Log/InternalModule/LLMProxy.log`
- ç³»ç»Ÿåˆå§‹åŒ–: `Log/Other/SystemInitializer.log`

### å¥åº·æ£€æŸ¥
```python
# æ£€æŸ¥ä»£ç†æ¨¡å—å¥åº·çŠ¶æ€
health_status = await llm_proxy.check_health()
print(f"LLMä»£ç†å¥åº·çŠ¶æ€: {health_status}")
```

## ğŸ‰ æ¼”ç¤ºè¿è¡Œ

è¿è¡Œå®Œæ•´æ¼”ç¤ºï¼š
```bash
cd Init/ServiceDiscovery
python demo_service_discovery.py
```

## ğŸ”„ ä»æ—§æ¶æ„è¿ç§»

å¦‚æœéœ€è¦å›é€€åˆ°æ—§æ¶æ„ï¼š
```python
# ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼
initializer = SystemInitializer(use_service_discovery=False)
```

---

## æ€»ç»“

æ–°çš„æœåŠ¡å‘ç°æ¶æ„ä¸ºæ‚¨çš„Agentç³»ç»Ÿæä¾›äº†ï¼š
- ğŸ­ **ç”Ÿäº§çº§åˆ«çš„å¯é æ€§**
- ğŸ”§ **çµæ´»çš„éƒ¨ç½²é€‰é¡¹**  
- ğŸ“ˆ **è‰¯å¥½çš„æ‰©å±•æ€§**
- ğŸ› ï¸ **æ˜“äºç»´æŠ¤**

å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨æœåŠ¡å‘ç°æ¨¡å¼ï¼Œåœ¨å¼€å‘ç¯å¢ƒä¸­å¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©åˆé€‚çš„æ¨¡å¼ã€‚
