# TODO 配置GOT-OCR2.0的环境是出现问题，cuda的问题，等显卡到了在解决
# 卡在了 ： pip install flash-attn --no-build-isolation
# 这一步上，目前已清除GOT-OCR2.0这个conda环境的所有nvdia包，等显卡到了再试试
"""
    FlashAttention 是一种高效的注意力机制实现，专门设计用来加速 Transformer 模型中的注意力计算
"""